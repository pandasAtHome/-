注：<b style="color: red">优先使用参数优化，其次代码优化</b>

# 资源参数

## executor 资源占比

| 用途      | 占比 | 说明                                                         |
| --------- | ---- | ------------------------------------------------------------ |
| storage   | 60%  | 用于：cache、persist、broadcast                              |
| 执行 task | 20%  | 1、执行任务计算：join、agg、shuffle等<br />1）若内存不足，写磁盘<br />2、task执行速度：<br />1）1个 CPU Core 执行1个线程<br />2）每个 executor 分配多个 task |
| other     | 20%  |                                                              |

## 参数

| 参数                           | 建议值   | 说明                                                         |
| ------------------------------ | -------- | ------------------------------------------------------------ |
| `num-executors`                | 50~100个 | 1、说明：该作业总共需要多少 executor 进程执行<br />（普通任务十几个或几十个即可） |
| `executor-memory`              | 4~8G     | 1、说明：每个 executor 进程的内存<br />2、总内存 = `num-executors * executor-memory`<br />（不超过`总内存`的 1/3 ~ 1/2） |
| `executor-cores`               | 2~4个    | 1、说明：每个 executor 进程的 CPU Core 数量<br />2、作用：决定每个 executor 进程并行执行 task 线程的能力<br />3、`作业申请总 CPU Core 数 = num-executors * executor-cores`<br />（不超过`总 CPU Core` 的 1/3 ~ 1/2） |
| `driver-memory`                | 1G       | 1、一般情况下，使用默认设置的 1G 即可<br />2、使用 `collect` 算子时，需要确保该值足够大（避免 OOM 内存溢出） |
| `spark.default.parallelism`    | 500~1000 | 1、说明：每个 stage 的默认 task 数量<br />2、默认 1个 HDFS 的 Block 对应1个 task（默认值偏小，可能导致资源利用不充分） |
| `spark.storage.memoryFraction` | 0.6      | 1、说明：RDD 持久化数据占 executor 内存的比例<br />2、持久化操作较多时，可增加 |
| `spark.shuffle.memoryFraction` | 0.2      | 1、说明：聚合操作占 executor 内存的比例<br />2、持久化较少、shuffle 较多，可增加 |

## 示例

```shell
./bin/spark-submit \
	--master yarn-cluster \
	--num-executors 100 \
	--executor-memory 6G \
	--executor-cores 4 \
	--driver-memory 1G \
	--conf spark.default.parallelism=1000 \
	--conf spark.storage.memoryFraction=0.5 \
	--conf spark.shuffle.memoryFraction=0.3 \
	...
```

# 开发调优

## RDD 复用

- 对于同一份数据，只创建一个 RDD

```scala

```

## RDD 持久化

- 对象：被别的 RDD 依赖，需多次重复计算
- 优化：
  - 使用 `Kryo 序列化机制`：节省 2~5 倍空间
  - 设置 `storage_level = MEMORY_AND_DISK_SER` （内存开销较大）

## 尽量避免 shuffle

- 常见 shuffle 算子：groupByKey、join、reduceByKey、distinct、repartition 等
- 示例

```scala
// 有 shuffle
val rdd3 = rdd1.join(rdd2)

// 避免 shuffle
val rdd2Data = rdd2.collect()
val rdd2DataBC = sc.broadcast(rdd2Data)
val rdd3 = rdd1.map(rdd2DataBC ...)
```

## 巧用 filter

- 尽可能早的执行 `filter` 操作，过滤无用数据
- `filter` 之后，使用 `coalesce` 对数据进行重分区

## 使用高性能算子

- 避免使用 `groupByKey`，根据场景使用 `reduceByKey`、`aggregateByKey`
- `coalesce`、`repartition`，在可能的情况下优先选择没有 shuffle 的操作
- `foreachPartition` 优化输出操作
- `mapPartitions` 性能比 `map` 好（数据大时，容易导致 OOM）
- 用 `repartitionAndSortWithinPartitions` 代替 `repartition + sort` 操作
- 合理使用 `cache`、`persist`、`checkpoint`（选择合理的存储级别）
- 减少对数据源的扫描

## 设置合理的并行度

- 并行度：各个 stage 的 task 数量
- 资源充足 =》设置尽可能大

## 广播大变量

- 默认情况：
  - task 中的算子 =》使用外部变量 =》 每个 task 获取一份变量副本 =》 造成多余的网络传输和内存消耗
- 广播变量：
  - 每个 Executor 保存一个副本 =》所有 task 共用此广播变量 =》节省网络及内存资源